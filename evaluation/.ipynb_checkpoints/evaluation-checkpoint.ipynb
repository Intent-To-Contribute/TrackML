{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import find_nearest_hit, scan_voxels_for_hits, sort_tracks\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from trackml.dataset import load_event\n",
    "from trackml.score import score_event\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = \"../../Data/train_100_events/\"\n",
    "event_path = \"event000001052\"\n",
    "\n",
    "hits, cells, particles, truth = load_event(path_to_dataset + event_path)\n",
    "true_tracks = np.load(\"../port_toy/all_tracks.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Voxels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished creating voxels\n"
     ]
    }
   ],
   "source": [
    "## find min/max of x,y,z ##\n",
    "xMax = -sys.maxsize\n",
    "yMax = -sys.maxsize\n",
    "zMax = -sys.maxsize\n",
    "xMin = sys.maxsize\n",
    "yMin = sys.maxsize\n",
    "zMin = sys.maxsize\n",
    "for track in true_tracks:\n",
    "    for hit in track:\n",
    "        if (xMax < hit[2]): xMax = hit[2]\n",
    "        if (yMax < hit[3]): yMax = hit[3]\n",
    "        if (zMax < hit[4]): zMax = hit[4]\n",
    "        if (xMin > hit[2]): xMin = hit[2]\n",
    "        if (yMin > hit[3]): yMin = hit[3]\n",
    "        if (zMin > hit[4]): zMin = hit[4]\n",
    "\n",
    "## creating voxels ##\n",
    "hits = np.asarray(hits)\n",
    "xRange = xMax - xMin\n",
    "yRange = yMax - yMin\n",
    "zRange = zMax - zMin\n",
    "n = 150\n",
    "voxels = np.zeros((n+1,n+1,n+1), dtype=object)\n",
    "\n",
    "for hit in hits:\n",
    "    xHit = hit[1]\n",
    "    yHit = hit[2]\n",
    "    zHit = hit[3]\n",
    "    i = int(n * ((xHit - xMin) / xRange))\n",
    "    j = int(n * ((yHit - yMin) / yRange))\n",
    "    k = int(n * ((zHit - zMin) / zRange))\n",
    "    if voxels[i][j][k] == 0:\n",
    "        voxels[i][j][k] = []\n",
    "    voxels[i][j][k].append(hit)\n",
    "\n",
    "print(\"finished creating voxels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with 9146 seed hits\n"
     ]
    }
   ],
   "source": [
    "### seeds ###\n",
    "seed_file = open(\"SeedCandidates.txt\", \"r\")\n",
    "our_tracks = []\n",
    "seed_hits = []\n",
    "for seed_id in seed_file:\n",
    "    seed_id = int(float(seed_id.strip()))\n",
    "    seed_hit = hits[hits[:,0] == seed_id][0]\n",
    "    our_tracks.append([int(seed_hit[0])])\n",
    "    seed_hits.append(seed_hit)\n",
    "\n",
    "# print(our_tracks)\n",
    "print(\"starting with \" + str(len(seed_hits)) + \" seed hits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Predicted Seeds ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5446 / 7842  seeds found with 9146 predicted.\n",
      "recall 0.6944656975261413\n",
      "precision 0.5954515635250383\n"
     ]
    }
   ],
   "source": [
    "true_seed_ids = []\n",
    "for track in true_tracks:\n",
    "    true_seed_ids.append(track[0][0])\n",
    "\n",
    "seed_ids = []\n",
    "for seed_hit in seed_hits:\n",
    "    seed_ids.append(seed_hit[0])\n",
    "\n",
    "found_seeds = np.isin(seed_ids, true_seed_ids)\n",
    "num_seeds_found = np.count_nonzero(found_seeds)\n",
    "num_seeds_guessed = len(seed_hits)\n",
    "num_real_seeds = len(true_seed_ids)\n",
    "\n",
    "print(num_seeds_found, \"/\", num_real_seeds, \" seeds found with\", num_seeds_guessed, \"predicted.\")\n",
    "print(\"recall\", num_seeds_found / num_real_seeds)\n",
    "print(\"precision\", num_seeds_found / num_seeds_guessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 500)               1008000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1503      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,009,503\n",
      "Trainable params: 1,009,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## predict the next point ##\n",
    "import tensorflow as tensorflow\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "## Import the stopping model\n",
    "# stopping_model = load_model(\"final_classifier.keras\")\n",
    "\n",
    "model = load_model(\"3in_3out.keras\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 2nd Hit from True Seeds ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7842, 18, 3)\n"
     ]
    }
   ],
   "source": [
    "true_seed_hits = []\n",
    "for track in true_tracks:\n",
    "    true_seed_hits.append(track[0])\n",
    "\n",
    "x = []\n",
    "for seed_hit in true_seed_hits:\n",
    "    input_vector = np.zeros((18, 3))\n",
    "    input_vector[17] = seed_hit[1:4]\n",
    "    x.append(input_vector)\n",
    "\n",
    "x = np.asarray(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (7842, 3)\n",
      "finished predicting 2nd hits\n",
      "[[708.31995  -71.86611  -63.708   ]\n",
      " [708.32     -71.8661   -63.708027]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(x)\n",
    "print(\"shape of predictions\", y.shape)\n",
    "print(\"finished predicting 2nd hits\")\n",
    "\n",
    "print(np.unique(y, axis=0))\n",
    "\n",
    "# for line in y:\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/7842\n",
      "(17, 7)\n",
      "5000/7842\n",
      "(17, 7)\n",
      "finished finding closest hits to predictions\n"
     ]
    }
   ],
   "source": [
    "## for each prediction, find the closest hit to it ##\n",
    "second_hits = []\n",
    "counter = 0\n",
    "for guess in y:    \n",
    "    xHit = guess[0]\n",
    "    yHit = guess[1]\n",
    "    zHit = guess[2]\n",
    "    i = int(n * ((xHit - xMin) / xRange))\n",
    "    j = int(n * ((yHit - yMin) / yRange))\n",
    "    k = int(n * ((zHit - zMin) / zRange))\n",
    "    \n",
    "    possible_nearest_hits = scan_voxels_for_hits(voxels, n, i, j, k)\n",
    "    second_hit = find_nearest_hit(possible_nearest_hits, guess)\n",
    "    second_hits.append(second_hit)\n",
    "    if (counter % 5000) == 0:\n",
    "        print(str(counter) + \"/\" + str(len(y)))\n",
    "        print(possible_nearest_hits.shape)\n",
    "    counter += 1\n",
    "\n",
    "print(\"finished finding closest hits to predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Predicted 2nd Hits ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique second IDs found: 1\n",
      "0 / 7400  second hits found with 7842 predicted.\n",
      "recall 0.0\n",
      "precision 0.0\n"
     ]
    }
   ],
   "source": [
    "true_second_ids = []\n",
    "for track in true_tracks:\n",
    "    if (len(track) > 2): true_second_ids.append(track[1][0])\n",
    "\n",
    "second_ids = []\n",
    "for second_hit in second_hits:\n",
    "    second_ids.append(second_hit[0])\n",
    "\n",
    "print(\"unique second IDs found:\", np.unique(np.asarray(second_ids)).shape[0])\n",
    "# print(true_second_ids)\n",
    "    \n",
    "found_seconds = np.isin(second_ids, true_second_ids)\n",
    "num_seconds_found = np.count_nonzero(found_seconds)\n",
    "num_seconds_guessed = len(second_hits)\n",
    "num_real_seconds = len(true_second_ids)\n",
    "\n",
    "\n",
    "\n",
    "print(num_seconds_found, \"/\", num_real_seconds, \" second hits found with\", num_seconds_guessed, \"predicted.\")\n",
    "print(\"recall\", num_seconds_found / num_real_seconds)\n",
    "print(\"precision\", num_seconds_found / num_seconds_guessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predict and Evaluate 3rd Hit from True (1st, 2nd) sequences ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 18, 3)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "true_hits = []\n",
    "max_len = 18\n",
    "for track in true_tracks:\n",
    "        i = 10\n",
    "#     for i in range(1, max_len):\n",
    "        x_hit = np.zeros((max_len, 3))\n",
    "\n",
    "        if i < len(track)-1:\n",
    "            for z in range(i):\n",
    "                x_hit[max_len-i+z] = track[z][2:5]\n",
    "            x.append(x_hit)\n",
    "            true_hits.append(np.append(track[i+1]))\n",
    "            \n",
    "x = np.asarray(x)\n",
    "print(x.shape)\n",
    "# print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of predictions (2304, 3)\n",
      "finished predicting hits\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(x)\n",
    "print(\"shape of predictions\", y.shape)\n",
    "print(\"finished predicting hits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2304\n",
      "(2, 7)\n",
      "finished finding closest hits to predictions\n",
      "(2304, 7)\n"
     ]
    }
   ],
   "source": [
    "predicted_hits = []\n",
    "counter = 0\n",
    "for guess in y:    \n",
    "    xHit = guess[0]\n",
    "    yHit = guess[1]\n",
    "    zHit = guess[2]\n",
    "    i = int(n * ((xHit - xMin) / xRange))\n",
    "    j = int(n * ((yHit - yMin) / yRange))\n",
    "    k = int(n * ((zHit - zMin) / zRange))\n",
    "    \n",
    "    possible_nearest_hits = scan_voxels_for_hits(voxels, n, i, j, k)\n",
    "    hit = find_nearest_hit(possible_nearest_hits, guess)\n",
    "    predicted_hits.append(hit)\n",
    "    if (counter % 5000) == 0:\n",
    "        print(str(counter) + \"/\" + str(len(y)))\n",
    "        print(possible_nearest_hits.shape)\n",
    "    counter += 1\n",
    "\n",
    "print(\"finished finding closest hits to predictions\")\n",
    "predicted_hits = np.asarray(predicted_hits)\n",
    "print(predicted_hits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[820.08502197  91.91850281 738.14202881 ...  86.00150299 996.13098145\n",
      "  62.70610046]\n",
      "unique IDs predicted: 1994\n",
      "0 / 2304  hits found with 2304 predicted.\n",
      "recall 0.0\n",
      "precision 0.0\n"
     ]
    }
   ],
   "source": [
    "true_ids = []\n",
    "for hit in true_y:\n",
    "    true_ids.append(hit[0])\n",
    "true_ids = np.asarray(true_ids)\n",
    "\n",
    "predicted_ids = []\n",
    "for hit in predicted_hits:\n",
    "    predicted_ids.append(hit[0])\n",
    "predicted_ids = np.asarray(predicted_ids)\n",
    "\n",
    "print(true_ids)\n",
    "\n",
    "print(\"unique IDs predicted:\", np.unique(np.asarray(predicted_ids)).shape[0])\n",
    "\n",
    "found = np.isin(predicted_ids, true_ids)\n",
    "num_true_found = np.count_nonzero(found)\n",
    "num_guessed = len(predicted_hits)\n",
    "num_true = len(true_ids)\n",
    "\n",
    "print(num_true_found, \"/\", num_true, \" hits found with\", num_guessed, \"predicted.\")\n",
    "print(\"recall\", num_true_found / num_true)\n",
    "print(\"precision\", num_true_found / num_guessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
